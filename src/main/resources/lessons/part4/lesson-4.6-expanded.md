# Lesson 3.6: Part 3 Capstone - Data Processing Pipeline

**Estimated Time**: 90 minutes
**Difficulty**: Advanced
**Prerequisites**: Lessons 3.1-3.5 (All functional programming concepts)

---

## Project Introduction

Congratulations on reaching the capstone project! You've learned functional programming from the ground upâ€”lambdas, higher-order functions, collection operations, scope functions, composition, and currying.

Now it's time to apply everything to a real-world project: a **Data Processing Pipeline** that analyzes sales data.

### What You'll Build

A complete functional data processing system that:
- Reads and parses CSV data
- Cleans and validates data
- Transforms and enriches data
- Aggregates statistics
- Generates reports
- Uses functional programming throughout

### Skills You'll Practice

âœ… Collection operations (map, filter, groupBy, etc.)
âœ… Higher-order functions
âœ… Function composition
âœ… Scope functions
âœ… Extension functions
âœ… Sequences for performance
âœ… Functional pipelines
âœ… Error handling functionally

---

## Project Requirements

### Dataset: Sales Data

You'll process sales data with these fields:
- Order ID
- Date
- Customer Name
- Product
- Category
- Quantity
- Price
- Region

### Features to Implement

**Core Features**:
1. Data parsing from CSV
2. Data validation and cleaning
3. Revenue calculation
4. Category-based analysis
5. Regional analysis
6. Top products/customers
7. Time-based trends
8. Report generation

**Functional Requirements**:
- Use functional pipelines (no imperative loops)
- Create reusable transformation functions
- Compose operations for complex analysis
- Use sequences for large datasets
- Apply scope functions appropriately

---

## Sample Data

```
OrderID,Date,Customer,Product,Category,Quantity,Price,Region
1001,2024-01-15,Alice Johnson,Laptop,Electronics,1,1200.00,North
1002,2024-01-16,Bob Smith,Mouse,Electronics,2,25.00,South
1003,2024-01-17,Alice Johnson,Keyboard,Electronics,1,75.00,North
1004,2024-01-18,Charlie Brown,Desk,Furniture,1,300.00,East
1005,2024-01-19,Diana Prince,Chair,Furniture,2,150.00,West
1006,2024-01-20,Bob Smith,Monitor,Electronics,1,400.00,South
1007,2024-01-21,Alice Johnson,Lamp,Furniture,3,50.00,North
1008,2024-01-22,Eve Davis,Laptop,Electronics,1,1200.00,East
1009,2024-01-23,Frank Miller,Mouse,Electronics,5,25.00,West
1010,2024-01-24,Charlie Brown,Desk,Furniture,1,300.00,East
1011,2024-01-25,Alice Johnson,Monitor,Electronics,1,400.00,North
1012,2024-01-26,Bob Smith,Keyboard,Electronics,2,75.00,South
1013,2024-01-27,Diana Prince,Laptop,Electronics,1,1200.00,West
1014,2024-01-28,Eve Davis,Chair,Furniture,2,150.00,East
1015,2024-01-29,Frank Miller,Lamp,Furniture,1,50.00,West
```

---

## Step 1: Data Model

First, define your data structures.

```kotlin
data class SalesRecord(
    val orderId: Int,
    val date: String,
    val customer: String,
    val product: String,
    val category: String,
    val quantity: Int,
    val price: Double,
    val region: String
) {
    val revenue: Double
        get() = quantity * price
}

// Result types for functional error handling
sealed class ParseResult {
    data class Success(val records: List<SalesRecord>) : ParseResult()
    data class Error(val message: String, val lineNumber: Int) : ParseResult()
}
```

---

## Step 2: CSV Parser

Create a functional CSV parser.

```kotlin
object CsvParser {
    fun parseLine(line: String, lineNumber: Int): SalesRecord? {
        return try {
            val parts = line.split(",")
            if (parts.size != 8) return null

            SalesRecord(
                orderId = parts[0].toInt(),
                date = parts[1],
                customer = parts[2],
                product = parts[3],
                category = parts[4],
                quantity = parts[5].toInt(),
                price = parts[6].toDouble(),
                region = parts[7]
            )
        } catch (e: Exception) {
            println("Error parsing line $lineNumber: ${e.message}")
            null
        }
    }

    fun parseCSV(csvData: String): List<SalesRecord> {
        return csvData
            .lines()
            .drop(1)  // Skip header
            .filter { it.isNotBlank() }
            .mapIndexedNotNull { index, line -> parseLine(line, index + 2) }
    }
}
```

---

## Step 3: Validation Pipeline

Create data validation functions.

```kotlin
// Validation functions
typealias Validator<T> = (T) -> Boolean

object Validators {
    val validQuantity: Validator<SalesRecord> = { it.quantity > 0 }
    val validPrice: Validator<SalesRecord> = { it.price > 0 }
    val validCustomer: Validator<SalesRecord> = { it.customer.isNotBlank() }
    val validProduct: Validator<SalesRecord> = { it.product.isNotBlank() }

    fun validateRecord(record: SalesRecord): Boolean {
        return listOf(
            validQuantity,
            validPrice,
            validCustomer,
            validProduct
        ).all { it(record) }
    }
}

// Extension function for validation
fun List<SalesRecord>.validated(): List<SalesRecord> {
    return this.filter(Validators::validateRecord)
}
```

---

## Step 4: Data Transformation Pipeline

Create transformation and enrichment functions.

```kotlin
// Extension functions for transformations
fun SalesRecord.normalize() = this.copy(
    customer = customer.trim(),
    product = product.trim(),
    category = category.trim(),
    region = region.trim().uppercase()
)

fun List<SalesRecord>.normalized() = this.map { it.normalize() }

// Revenue calculations
fun List<SalesRecord>.totalRevenue() = this.sumOf { it.revenue }

fun List<SalesRecord>.averageOrderValue() =
    if (this.isEmpty()) 0.0 else this.totalRevenue() / this.size
```

---

## Step 5: Analysis Functions

Create analysis functions using functional operations.

```kotlin
object Analytics {
    // Category analysis
    fun categoryBreakdown(records: List<SalesRecord>): Map<String, Double> {
        return records
            .groupBy { it.category }
            .mapValues { (_, sales) -> sales.totalRevenue() }
    }

    // Regional analysis
    fun regionalBreakdown(records: List<SalesRecord>): Map<String, Double> {
        return records
            .groupBy { it.region }
            .mapValues { (_, sales) -> sales.totalRevenue() }
    }

    // Top products
    fun topProducts(records: List<SalesRecord>, limit: Int = 5): List<Pair<String, Double>> {
        return records
            .groupBy { it.product }
            .mapValues { (_, sales) -> sales.totalRevenue() }
            .toList()
            .sortedByDescending { it.second }
            .take(limit)
    }

    // Top customers
    fun topCustomers(records: List<SalesRecord>, limit: Int = 5): List<Pair<String, Double>> {
        return records
            .groupBy { it.customer }
            .mapValues { (_, sales) -> sales.totalRevenue() }
            .toList()
            .sortedByDescending { it.second }
            .take(limit)
    }

    // Product statistics
    data class ProductStats(
        val totalOrders: Int,
        val totalQuantity: Int,
        val totalRevenue: Double,
        val averagePrice: Double
    )

    fun productStatistics(records: List<SalesRecord>): Map<String, ProductStats> {
        return records
            .groupBy { it.product }
            .mapValues { (_, sales) ->
                ProductStats(
                    totalOrders = sales.size,
                    totalQuantity = sales.sumOf { it.quantity },
                    totalRevenue = sales.totalRevenue(),
                    averagePrice = sales.map { it.price }.average()
                )
            }
    }
}
```

---

## Step 6: Report Generator

Create a report generator using functional composition.

```kotlin
object ReportGenerator {
    fun generateSummary(records: List<SalesRecord>): String {
        return buildString {
            appendLine("=" .repeat(60))
            appendLine("SALES REPORT SUMMARY")
            appendLine("=".repeat(60))
            appendLine()

            appendLine("ðŸ“Š Overall Statistics")
            appendLine("-".repeat(60))
            appendLine("Total Orders: ${records.size}")
            appendLine("Total Revenue: ${"$%.2f".format(records.totalRevenue())}")
            appendLine("Average Order Value: ${"$%.2f".format(records.averageOrderValue())}")
            appendLine()

            val categoryData = Analytics.categoryBreakdown(records)
            appendLine("ðŸ“¦ Category Breakdown")
            appendLine("-".repeat(60))
            categoryData
                .toList()
                .sortedByDescending { it.second }
                .forEach { (category, revenue) ->
                    appendLine("  $category: ${"$%.2f".format(revenue)}")
                }
            appendLine()

            val regionalData = Analytics.regionalBreakdown(records)
            appendLine("ðŸŒ Regional Breakdown")
            appendLine("-".repeat(60))
            regionalData
                .toList()
                .sortedByDescending { it.second }
                .forEach { (region, revenue) ->
                    appendLine("  $region: ${"$%.2f".format(revenue)}")
                }
            appendLine()

            appendLine("ðŸ† Top 5 Products")
            appendLine("-".repeat(60))
            Analytics.topProducts(records, 5)
                .forEachIndexed { index, (product, revenue) ->
                    appendLine("  ${index + 1}. $product: ${"$%.2f".format(revenue)}")
                }
            appendLine()

            appendLine("ðŸ‘¥ Top 5 Customers")
            appendLine("-".repeat(60))
            Analytics.topCustomers(records, 5)
                .forEachIndexed { index, (customer, revenue) ->
                    appendLine("  ${index + 1}. $customer: ${"$%.2f".format(revenue)}")
                }
            appendLine()

            appendLine("=".repeat(60))
        }
    }

    fun generateDetailedReport(records: List<SalesRecord>): String {
        return buildString {
            appendLine(generateSummary(records))
            appendLine()
            appendLine("ðŸ“Š DETAILED PRODUCT STATISTICS")
            appendLine("=".repeat(60))

            Analytics.productStatistics(records)
                .toList()
                .sortedByDescending { it.second.totalRevenue }
                .forEach { (product, stats) ->
                    appendLine()
                    appendLine("Product: $product")
                    appendLine("  Orders: ${stats.totalOrders}")
                    appendLine("  Quantity Sold: ${stats.totalQuantity}")
                    appendLine("  Total Revenue: ${"$%.2f".format(stats.totalRevenue)}")
                    appendLine("  Average Price: ${"$%.2f".format(stats.averagePrice)}")
                }
        }
    }
}
```

---

## Step 7: Complete Pipeline

Put it all together in a functional pipeline.

```kotlin
class SalesDataPipeline {
    private val transformations = mutableListOf<(List<SalesRecord>) -> List<SalesRecord>>()

    fun addTransformation(transform: (List<SalesRecord>) -> List<SalesRecord>) = apply {
        transformations.add(transform)
    }

    fun process(csvData: String): List<SalesRecord> {
        var records = CsvParser.parseCSV(csvData)

        // Apply all transformations in sequence
        transformations.forEach { transform ->
            records = transform(records)
        }

        return records
    }
}

// Create pipeline
fun createPipeline() = SalesDataPipeline()
    .addTransformation { it.validated() }
    .addTransformation { it.normalized() }

// Infix function for readable filtering
infix fun List<SalesRecord>.inCategory(category: String) =
    this.filter { it.category.equals(category, ignoreCase = true) }

infix fun List<SalesRecord>.inRegion(region: String) =
    this.filter { it.region.equals(region, ignoreCase = true) }

fun List<SalesRecord>.withRevenueAbove(amount: Double) =
    this.filter { it.revenue > amount }
```

---

## Complete Solution

Here's the full working solution:

```kotlin
// Data Model
data class SalesRecord(
    val orderId: Int,
    val date: String,
    val customer: String,
    val product: String,
    val category: String,
    val quantity: Int,
    val price: Double,
    val region: String
) {
    val revenue: Double get() = quantity * price
}

// CSV Parser
object CsvParser {
    fun parseLine(line: String): SalesRecord? {
        return try {
            val parts = line.split(",")
            if (parts.size != 8) return null
            SalesRecord(
                orderId = parts[0].toInt(),
                date = parts[1],
                customer = parts[2],
                product = parts[3],
                category = parts[4],
                quantity = parts[5].toInt(),
                price = parts[6].toDouble(),
                region = parts[7]
            )
        } catch (e: Exception) {
            null
        }
    }

    fun parseCSV(csvData: String): List<SalesRecord> {
        return csvData.lines()
            .drop(1)
            .filter { it.isNotBlank() }
            .mapNotNull { parseLine(it) }
    }
}

// Validators
object Validators {
    val validQuantity: (SalesRecord) -> Boolean = { it.quantity > 0 }
    val validPrice: (SalesRecord) -> Boolean = { it.price > 0 }
    val validCustomer: (SalesRecord) -> Boolean = { it.customer.isNotBlank() }

    fun validateRecord(record: SalesRecord): Boolean =
        listOf(validQuantity, validPrice, validCustomer).all { it(record) }
}

// Extensions
fun SalesRecord.normalize() = copy(
    customer = customer.trim(),
    product = product.trim(),
    category = category.trim(),
    region = region.trim().uppercase()
)

fun List<SalesRecord>.validated() = filter(Validators::validateRecord)
fun List<SalesRecord>.normalized() = map { it.normalize() }
fun List<SalesRecord>.totalRevenue() = sumOf { it.revenue }
fun List<SalesRecord>.averageOrderValue() =
    if (isEmpty()) 0.0 else totalRevenue() / size

infix fun List<SalesRecord>.inCategory(category: String) =
    filter { it.category.equals(category, ignoreCase = true) }

infix fun List<SalesRecord>.inRegion(region: String) =
    filter { it.region.equals(region, ignoreCase = true) }

// Analytics
object Analytics {
    fun categoryBreakdown(records: List<SalesRecord>) =
        records.groupBy { it.category }
            .mapValues { (_, sales) -> sales.totalRevenue() }

    fun regionalBreakdown(records: List<SalesRecord>) =
        records.groupBy { it.region }
            .mapValues { (_, sales) -> sales.totalRevenue() }

    fun topProducts(records: List<SalesRecord>, limit: Int = 5) =
        records.groupBy { it.product }
            .mapValues { (_, sales) -> sales.totalRevenue() }
            .toList()
            .sortedByDescending { it.second }
            .take(limit)

    fun topCustomers(records: List<SalesRecord>, limit: Int = 5) =
        records.groupBy { it.customer }
            .mapValues { (_, sales) -> sales.totalRevenue() }
            .toList()
            .sortedByDescending { it.second }
            .take(limit)
}

// Report Generator
object ReportGenerator {
    fun generate(records: List<SalesRecord>): String = buildString {
        appendLine("=" .repeat(60))
        appendLine("SALES REPORT")
        appendLine("=".repeat(60))
        appendLine()

        appendLine("ðŸ“Š Overall Statistics")
        appendLine("Total Orders: ${records.size}")
        appendLine("Total Revenue: ${"$%.2f".format(records.totalRevenue())}")
        appendLine("Average Order: ${"$%.2f".format(records.averageOrderValue())}")
        appendLine()

        appendLine("ðŸ“¦ Category Breakdown")
        Analytics.categoryBreakdown(records)
            .toList()
            .sortedByDescending { it.second }
            .forEach { (cat, rev) ->
                appendLine("  $cat: ${"$%.2f".format(rev)}")
            }
        appendLine()

        appendLine("ðŸŒ Regional Breakdown")
        Analytics.regionalBreakdown(records)
            .toList()
            .sortedByDescending { it.second }
            .forEach { (reg, rev) ->
                appendLine("  $reg: ${"$%.2f".format(rev)}")
            }
        appendLine()

        appendLine("ðŸ† Top 5 Products")
        Analytics.topProducts(records, 5)
            .forEachIndexed { i, (prod, rev) ->
                appendLine("  ${i + 1}. $prod: ${"$%.2f".format(rev)}")
            }
        appendLine()

        appendLine("ðŸ‘¥ Top 5 Customers")
        Analytics.topCustomers(records, 5)
            .forEachIndexed { i, (cust, rev) ->
                appendLine("  ${i + 1}. $cust: ${"$%.2f".format(rev)}")
            }
    }
}

// Main Application
fun main() {
    val csvData = """
OrderID,Date,Customer,Product,Category,Quantity,Price,Region
1001,2024-01-15,Alice Johnson,Laptop,Electronics,1,1200.00,North
1002,2024-01-16,Bob Smith,Mouse,Electronics,2,25.00,South
1003,2024-01-17,Alice Johnson,Keyboard,Electronics,1,75.00,North
1004,2024-01-18,Charlie Brown,Desk,Furniture,1,300.00,East
1005,2024-01-19,Diana Prince,Chair,Furniture,2,150.00,West
1006,2024-01-20,Bob Smith,Monitor,Electronics,1,400.00,South
1007,2024-01-21,Alice Johnson,Lamp,Furniture,3,50.00,North
1008,2024-01-22,Eve Davis,Laptop,Electronics,1,1200.00,East
1009,2024-01-23,Frank Miller,Mouse,Electronics,5,25.00,West
1010,2024-01-24,Charlie Brown,Desk,Furniture,1,300.00,East
1011,2024-01-25,Alice Johnson,Monitor,Electronics,1,400.00,North
1012,2024-01-26,Bob Smith,Keyboard,Electronics,2,75.00,South
1013,2024-01-27,Diana Prince,Laptop,Electronics,1,1200.00,West
1014,2024-01-28,Eve Davis,Chair,Furniture,2,150.00,East
1015,2024-01-29,Frank Miller,Lamp,Furniture,1,50.00,West
    """.trimIndent()

    // Process data through functional pipeline
    val allRecords = CsvParser.parseCSV(csvData)
        .validated()
        .normalized()

    println("Processed ${allRecords.size} records\n")

    // Generate full report
    println(ReportGenerator.generate(allRecords))

    // Demonstrate functional filtering
    println("\n" + "=".repeat(60))
    println("CUSTOM ANALYSIS EXAMPLES")
    println("=".repeat(60))

    // Electronics in North region
    val northElectronics = allRecords inCategory "Electronics" inRegion "NORTH"
    println("\nElectronics in North Region:")
    println("  Orders: ${northElectronics.size}")
    println("  Revenue: ${"$%.2f".format(northElectronics.totalRevenue())}")

    // Furniture analysis
    val furniture = allRecords inCategory "Furniture"
    println("\nFurniture Sales:")
    println("  Orders: ${furniture.size}")
    println("  Revenue: ${"$%.2f".format(furniture.totalRevenue())}")
    println("  Average Order: ${"$%.2f".format(furniture.averageOrderValue())}")

    // High-value orders
    val highValue = allRecords.filter { it.revenue > 500 }
    println("\nHigh-Value Orders (>$500):")
    println("  Count: ${highValue.size}")
    println("  Total: ${"$%.2f".format(highValue.totalRevenue())}")
}
```

---

## Extension Challenges

Take the project further with these challenges!

### Challenge 1: Date-Based Analysis

Add time-series analysis:

```kotlin
// Parse dates and group by month
fun List<SalesRecord>.byMonth(): Map<String, List<SalesRecord>> {
    return this.groupBy { record ->
        record.date.substring(0, 7)  // Extract YYYY-MM
    }
}

fun List<SalesRecord>.monthlyTrend(): List<Pair<String, Double>> {
    return this.byMonth()
        .mapValues { (_, records) -> records.totalRevenue() }
        .toList()
        .sortedBy { it.first }
}
```

### Challenge 2: Customer Segmentation

Classify customers by spending:

```kotlin
enum class CustomerTier { BRONZE, SILVER, GOLD, PLATINUM }

fun classifyCustomer(totalSpending: Double): CustomerTier = when {
    totalSpending >= 2000 -> CustomerTier.PLATINUM
    totalSpending >= 1000 -> CustomerTier.GOLD
    totalSpending >= 500 -> CustomerTier.SILVER
    else -> CustomerTier.BRONZE
}

fun List<SalesRecord>.customerTiers(): Map<String, CustomerTier> {
    return this.groupBy { it.customer }
        .mapValues { (_, records) ->
            classifyCustomer(records.totalRevenue())
        }
}
```

### Challenge 3: Product Recommendations

Find frequently bought together items:

```kotlin
fun List<SalesRecord>.productPairs(): Map<Pair<String, String>, Int> {
    return this.groupBy { it.orderId }
        .values
        .flatMap { orderRecords ->
            val products = orderRecords.map { it.product }
            products.flatMapIndexed { i, p1 ->
                products.drop(i + 1).map { p2 ->
                    if (p1 < p2) p1 to p2 else p2 to p1
                }
            }
        }
        .groupingBy { it }
        .eachCount()
}
```

### Challenge 4: Export to Different Formats

Add JSON/CSV export:

```kotlin
fun List<SalesRecord>.toJson(): String {
    return this.joinToString(",\n  ", "[\n  ", "\n]") { record ->
        """
        {
          "orderId": ${record.orderId},
          "customer": "${record.customer}",
          "revenue": ${record.revenue}
        }
        """.trimIndent()
    }
}

fun Map<String, Double>.toCsv(): String {
    return this.toList()
        .joinToString("\n", "Category,Revenue\n") { (key, value) ->
            "$key,${"%.2f".format(value)}"
        }
}
```

### Challenge 5: Sequence Optimization

Use sequences for large datasets:

```kotlin
fun processLargeDataset(csvData: String): List<SalesRecord> {
    return csvData.lineSequence()  // Sequence instead of lines()
        .drop(1)
        .filter { it.isNotBlank() }
        .mapNotNull { CsvParser.parseLine(it) }
        .filter(Validators::validateRecord)
        .map { it.normalize() }
        .toList()
}
```

---

## Testing Your Pipeline

Create test functions to verify your implementation:

```kotlin
fun testPipeline() {
    val testData = """
OrderID,Date,Customer,Product,Category,Quantity,Price,Region
1,2024-01-01,Test User,Test Product,Test,1,100.00,North
2,2024-01-02,Test User,Test Product,Test,2,50.00,South
    """.trimIndent()

    val records = CsvParser.parseCSV(testData).validated().normalized()

    // Test parsing
    assert(records.size == 2) { "Should parse 2 records" }

    // Test revenue calculation
    val total = records.totalRevenue()
    assert(total == 200.0) { "Total revenue should be 200" }

    // Test filtering
    val north = records inRegion "NORTH"
    assert(north.size == 1) { "Should find 1 North region record" }

    println("âœ… All tests passed!")
}
```

---

## What You've Accomplished

**Functional Programming Techniques Used**:
- âœ… Higher-order functions (map, filter, groupBy)
- âœ… Function composition and pipelines
- âœ… Extension functions for fluent APIs
- âœ… Scope functions (apply, let, also)
- âœ… Infix functions for readability
- âœ… Sequences for performance
- âœ… Functional error handling
- âœ… Type-safe transformations
- âœ… Immutable data structures
- âœ… Declarative data processing

**Real-World Skills**:
- CSV parsing and data import
- Data validation and cleaning
- Statistical analysis
- Report generation
- Modular, reusable code design
- Performance optimization

---

## Checkpoint Quiz

### Question 1
Why use sequences instead of lists for large datasets?

A) Sequences are faster for all operations
B) Sequences use lazy evaluation, processing elements only as needed
C) Sequences use less memory for small datasets
D) Sequences can't be used with collection operations

### Question 2
What's the benefit of extension functions in the pipeline?

A) They make code run faster
B) They create fluent, chainable APIs that read naturally
C) They're required for functional programming
D) They reduce memory usage

### Question 3
Why use `mapNotNull` instead of `map`?

A) It's faster
B) It filters out null values automatically while mapping
C) It handles exceptions better
D) There's no difference

### Question 4
What does the `infix` keyword enable in `inCategory`?

A) Faster execution
B) Calling the function without dot notation: `records inCategory "Electronics"`
C) Making the function private
D) Type safety

### Question 5
Why separate validation, transformation, and analysis into different objects/functions?

A) It's required by Kotlin
B) Separation of concerns: easier to test, reuse, and maintain
C) It makes code slower but safer
D) It uses less memory

---

## Quiz Answers

**Question 1: B) Sequences use lazy evaluation, processing elements only as needed**

```kotlin
// List: processes ALL elements at each step
val list = (1..1_000_000).toList()
    .map { it * 2 }        // Creates 1M element list
    .filter { it > 100 }   // Processes all 1M
    .take(10)

// Sequence: processes only what's needed
val sequence = (1..1_000_000).asSequence()
    .map { it * 2 }        // Lazy
    .filter { it > 100 }   // Lazy
    .take(10)              // Stops after 10 matches
    .toList()
```

Sequences excel with large data and partial results.

---

**Question 2: B) They create fluent, chainable APIs that read naturally**

```kotlin
// Without extensions
val result = normalize(validate(parse(data)))

// With extensions
val result = data
    .parse()
    .validate()
    .normalize()
```

Reads left-to-right, naturally chains operations.

---

**Question 3: B) It filters out null values automatically while mapping**

```kotlin
// With map: need separate filter
val numbers = input.map { it.toIntOrNull() }.filterNotNull()

// With mapNotNull: one operation
val numbers = input.mapNotNull { it.toIntOrNull() }
```

More concise and expresses intent clearly.

---

**Question 4: B) Calling the function without dot notation: `records inCategory "Electronics"`**

```kotlin
// Regular function
records.inCategory("Electronics")

// Infix function
records inCategory "Electronics"
```

Reads more naturally, like English.

---

**Question 5: B) Separation of concerns: easier to test, reuse, and maintain**

```kotlin
// Separated: easy to test each part
val parsed = CsvParser.parseCSV(data)
val validated = Validators.validate(parsed)
val analyzed = Analytics.analyze(validated)

// Each component can be:
// - Tested independently
// - Reused in different contexts
// - Modified without affecting others
// - Understood in isolation
```

Modular design is a core programming principle.

---

## Final Thoughts

**You've Built a Complete Functional Application!**

This capstone project demonstrates that functional programming isn't just academicâ€”it's practical and powerful for real-world applications.

**Key Lessons**:
1. **Composition**: Small functions â†’ Complex operations
2. **Immutability**: Safer, easier to reason about
3. **Declarative**: Expresses *what*, not *how*
4. **Reusability**: Functions as building blocks
5. **Testability**: Pure functions are easy to test

**Next Steps**:
- Add features from the extension challenges
- Apply FP principles to your own projects
- Explore Arrow library for advanced FP in Kotlin
- Practice composing functions daily

---

## Additional Resources

**Libraries for Functional Kotlin**:
- **Arrow**: Functional programming library (types, patterns)
- **Kotlinx.coroutines**: Asynchronous functional patterns
- **Exposed**: Functional SQL DSL

**Further Reading**:
- "Functional Programming in Kotlin" by Marco Vermeulen
- "Kotlin in Action" by Dmitry Jemerov
- Arrow documentation: arrow-kt.io

**Practice Projects**:
- Log analyzer with functional pipelines
- JSON/XML transformer
- Stream processing system
- Configuration validator

---

**Congratulations on completing Part 3: Functional Programming!** ðŸŽ‰

You've mastered:
- Functional programming fundamentals
- Lambda expressions and higher-order functions
- Collection operations and sequences
- Scope functions
- Function composition and currying
- Building real-world functional applications

These skills will make you a better programmer in any language. Functional thinking transcends Kotlinâ€”it's a way of approaching problems that leads to elegant, maintainable solutions.

Keep practicing, keep building, and enjoy the functional journey ahead!
